{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f45afe-a2de-492d-9045-3e03ee04084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,SQLContext,Row\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a099a108-3aef-4fd3-9743-b755e22bbe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/01 03:33:05 WARN Utils: Your hostname, wafa-VirtualBox resolves to a loopback address: 127.0.1.1; using 192.168.56.101 instead (on interface enp0s3)\n",
      "24/02/01 03:33:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/01 03:33:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName('ML_Model').getOrCreate() \n",
    "\n",
    "sq = SQLContext(sparkContext=sc.sparkContext, sparkSession=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c975e1-c7da-4f4c-b700-256a5dda8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = sq.read.csv(f'hdfs://192.168.56.102:8020/user/cloudera/heart_2022_no_nans.csv', inferSchema ='true' ,header='true',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37741977-c733-4524-a59a-74c9ee2da3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_pand = df.toPandas()\\ndf_pand.shape\\nprint(\"sex= \",df_pand[\"sex\"].unique())\\nprint(\"generalHealth =  \" ,df_pand[\"generalHealth\"].unique())\\nprint(\"PhysicalHealthDays= \",df_pand[\"PhysicalHealthDays\"].unique())\\nprint(\"physicalActivities= \",df_pand[\"physicalActivities\"].unique())\\nprint(\"removedTeeth= \",df_pand[\"removedTeeth\"].unique())\\nprint(\"hadAngina= \",df_pand[\"hadAngina\"].unique())\\nprint(\"hadStroke= \",df_pand[\"hadStroke\"].unique())\\nprint(\"hadCOPD= \",df_pand[\"hadCOPD\"].unique())\\nprint(\"hadKidneyDisease= \",df_pand[\"hadKidneyDisease\"].unique())\\nprint(\"hadArthritis= \",df_pand[\"hadArthritis\"].unique())\\nprint(\"hadDiabetes= \",df_pand[\"hadDiabetes\"].unique())\\nprint(\"deafOrHardOfHearing= \",df_pand[\"deafOrHardOfHearing\"].unique())\\nprint(\"blindOrVisionDifficulty= \",df_pand[\"blindOrVisionDifficulty\"].unique())\\nprint(\"difficultyWalking= \",df_pand[\"difficultyWalking\"].unique())\\nprint(\"difficultyDressingBathing= \",df_pand[\"difficultyDressingBathing\"].unique())\\nprint(\"difficultyErrands= \",df_pand[\"difficultyErrands\"].unique())\\nprint(\"smokerStatus= \",df_pand[\"smokerStatus\"].unique())\\nprint(\"chestScan= \",df_pand[\"chestScan\"].unique())\\nprint(\"ageCategory= \",df_pand[\"ageCategory\"].unique())\\nprint(\"alcoholDrinkers= \",df_pand[\"alcoholDrinkers\"].unique())\\nprint(\"pneumoVaxEver= \",df_pand[\"pneumoVaxEver\"].unique())'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_pand = df.toPandas()\n",
    "df_pand.shape\n",
    "print(\"sex= \",df_pand[\"sex\"].unique())\n",
    "print(\"generalHealth =  \" ,df_pand[\"generalHealth\"].unique())\n",
    "print(\"PhysicalHealthDays= \",df_pand[\"PhysicalHealthDays\"].unique())\n",
    "print(\"physicalActivities= \",df_pand[\"physicalActivities\"].unique())\n",
    "print(\"removedTeeth= \",df_pand[\"removedTeeth\"].unique())\n",
    "print(\"hadAngina= \",df_pand[\"hadAngina\"].unique())\n",
    "print(\"hadStroke= \",df_pand[\"hadStroke\"].unique())\n",
    "print(\"hadCOPD= \",df_pand[\"hadCOPD\"].unique())\n",
    "print(\"hadKidneyDisease= \",df_pand[\"hadKidneyDisease\"].unique())\n",
    "print(\"hadArthritis= \",df_pand[\"hadArthritis\"].unique())\n",
    "print(\"hadDiabetes= \",df_pand[\"hadDiabetes\"].unique())\n",
    "print(\"deafOrHardOfHearing= \",df_pand[\"deafOrHardOfHearing\"].unique())\n",
    "print(\"blindOrVisionDifficulty= \",df_pand[\"blindOrVisionDifficulty\"].unique())\n",
    "print(\"difficultyWalking= \",df_pand[\"difficultyWalking\"].unique())\n",
    "print(\"difficultyDressingBathing= \",df_pand[\"difficultyDressingBathing\"].unique())\n",
    "print(\"difficultyErrands= \",df_pand[\"difficultyErrands\"].unique())\n",
    "print(\"smokerStatus= \",df_pand[\"smokerStatus\"].unique())\n",
    "print(\"chestScan= \",df_pand[\"chestScan\"].unique())\n",
    "print(\"ageCategory= \",df_pand[\"ageCategory\"].unique())\n",
    "print(\"alcoholDrinkers= \",df_pand[\"alcoholDrinkers\"].unique())\n",
    "print(\"pneumoVaxEver= \",df_pand[\"pneumoVaxEver\"].unique())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2b971a-551d-48f9-8d08-dcb0b1dac1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sex: string (nullable = true)\n",
      " |-- generalHealth: string (nullable = true)\n",
      " |-- PhysicalHealthDays: double (nullable = true)\n",
      " |-- physicalActivities: string (nullable = true)\n",
      " |-- removedTeeth: string (nullable = true)\n",
      " |-- hadAngina: string (nullable = true)\n",
      " |-- hadStroke: string (nullable = true)\n",
      " |-- hadCOPD: string (nullable = true)\n",
      " |-- hadKidneyDisease: string (nullable = true)\n",
      " |-- hadArthritis: string (nullable = true)\n",
      " |-- hadDiabetes: string (nullable = true)\n",
      " |-- hadHeartAttack: string (nullable = true)\n",
      " |-- deafOrHardOfHearing: string (nullable = true)\n",
      " |-- blindOrVisionDifficulty: string (nullable = true)\n",
      " |-- difficultyWalking: string (nullable = true)\n",
      " |-- difficultyDressingBathing: string (nullable = true)\n",
      " |-- difficultyErrands: string (nullable = true)\n",
      " |-- smokerStatus: string (nullable = true)\n",
      " |-- chestScan: string (nullable = true)\n",
      " |-- ageCategory: string (nullable = true)\n",
      " |-- alcoholDrinkers: string (nullable = true)\n",
      " |-- pneumoVaxEver: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf858de-246e-4fff-b902-089962bf4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/01 03:34:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "input = [\"sex\",\"generalHealth\",\"PhysicalHealthDays\",\"physicalActivities\",\"removedTeeth\",\"hadAngina\",\"hadHeartAttack\",\"hadStroke\",\"hadCOPD\",\"hadKidneyDisease\",\"hadArthritis\",\n",
    "                 \"hadDiabetes\",\"deafOrHardOfHearing\",\"blindOrVisionDifficulty\",\"difficultyWalking\",\"difficultyDressingBathing\",\"difficultyErrands\",\"smokerStatus\",\"chestScan\",\n",
    "                  \"ageCategory\",\"alcoholDrinkers\",\"pneumoVaxEver\"]\n",
    "\n",
    "output = [\"Sex\",\"GeneralHealth\",\"physicalHealthDays\",\"PhysicalActivities\",\"RemovedTeeth\",\"HadAngina\",\"HadHeartAttack\",\"HadStroke\",\"HadCOPD\",\"HadKidneyDisease\",\"HadArthritis\",\n",
    "                 \"HadDiabetes\",\"DeafOrHardOfHearing\",\"BlindOrVisionDifficulty\",\"DifficultyWalking\",\"DifficultyDressingBathing\",\"DifficultyErrands\",\"SmokerStatus\",\"ChestScan\",\n",
    "                  \"AgeCategory\",\"AlcoholDrinkers\",\"PneumoVaxEver\"]\n",
    "\n",
    "encoder = StringIndexer(inputCols=input,outputCols=output)\n",
    "df_encoded = encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4e2d09-ddee-4c28-a35a-cfddabf53107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Sex: double, GeneralHealth: double, physicalHealthDays: double, PhysicalActivities: double, RemovedTeeth: double, HadAngina: double, HadStroke: double, HadCOPD: double, HadKidneyDisease: double, HadArthritis: double, HadDiabetes: double, HadHeartAttack: double, DeafOrHardOfHearing: double, BlindOrVisionDifficulty: double, DifficultyWalking: double, DifficultyDressingBathing: double, DifficultyErrands: double, SmokerStatus: double, ChestScan: double, AgeCategory: double, AlcoholDrinkers: double, PneumoVaxEver: double, features: vector]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cls = output = [\"Sex\",\"GeneralHealth\",\"physicalHealthDays\",\"PhysicalActivities\",\"RemovedTeeth\",\"HadAngina\",\"HadStroke\",\"HadCOPD\",\"HadKidneyDisease\",\"HadArthritis\",\n",
    "                 \"HadDiabetes\",\"DeafOrHardOfHearing\",\"BlindOrVisionDifficulty\",\"DifficultyWalking\",\"DifficultyDressingBathing\",\"DifficultyErrands\",\"SmokerStatus\",\"ChestScan\",\n",
    "                  \"AgeCategory\",\"AlcoholDrinkers\",\"PneumoVaxEver\"]\n",
    "vector_assembler = VectorAssembler(inputCols=features_cls, outputCol=\"features\")\n",
    "df_encoded = vector_assembler.transform(df_encoded)\n",
    "df_encoded \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac63542-b203-4a2a-8cfc-6723c19d3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_encoded.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a6ac70-bc92-4ec9-a689-23ae7265d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"HadHeartAttack\", featuresCol=\"features\")\n",
    "model = dt.fit(train_data)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7f46d9-2f55-4281-bf95-4d16be922dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"HadHeartAttack\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26b197d-2023-4b7c-b4f5-3ace87d1dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5913249635963841\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7b6859-f437-4bdd-97f6-26f3a5787795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/01 03:36:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8811438299345558\n"
     ]
    }
   ],
   "source": [
    "# the logistic regression model\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "target_column = \"HadHeartAttack\"\n",
    "\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.01, labelCol=target_column)\n",
    "\n",
    "# Fit the model \n",
    "model2 = lr.fit(train_data)\n",
    "# Make predictions \n",
    "predict = model2.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=target_column, metricName=\"areaUnderROC\")\n",
    "accuracy = evaluator.evaluate(predict)\n",
    "print(f\"accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1082e7a-54dd-4af1-b4a9-bf2e6d5ea17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC: 0.8811359872374415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5537270087124879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=target_column, rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# Area Under ROC\n",
    "roc_auc = evaluator.evaluate(predict)\n",
    "print(f\"accuracy: {roc_auc}\")\n",
    "\n",
    "true_positive = predict.filter((predict[target_column] == 1) & (predict['prediction'] == 1)).count()\n",
    "false_positive = predict.filter((predict[target_column] == 0) & (predict['prediction'] == 1)).count()\n",
    "\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5314a6-07de-4dfa-a99d-ba995ee81a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
